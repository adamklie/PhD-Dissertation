\chapter{Syntax-driven design of neural-specific enhancers in vivo}
\label{chap:Syntax-driven design of neural-specific enhancers in vivo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Enhancers are DNA sequences that control when and where genes are expressed {6409418}. They function as genetic switches that activate transcription of nearby genes when bound by transcription factor (TF) proteins, often in specific developmental stages or cell types {20833320}. Short sequence motifs called transcription factor binding sites (TFBS) drive enhancer activity {refs}, and many enhancers obey certain organizational rules for these TFBSs that go beyond their mere presence, often referred to as an enhancer’s “grammar” {33689769}. In this view, an enhancer’s function is not only controlled by the number, type, and affinity of the TFBSs it contains (the composition), but also by the relative order, orientation, and spacing of these sites (the syntax). Much like words in a sentence must be ordered correctly to convey meaning, the arrangement of TFBS can affect whether TFs cooperate or interfere, as TF proteins and DNA may have specific interaction requirements.

The specificity of many enhancers makes them attractive tools for use in gene therapy applications that require delivery of a gene to specific tissues or cell types. This has driven significant interest in the computational design of synthetic enhancers with tissue-specific regulatory activity. Many approaches leverage training of deep learning (DL) models to predict functional readouts from DNA sequence on large-scale genomic datasets, such as genome-wide chromatin accessibility profiles {Taskirin, de Almeida} or massively parallel reporter assays (MPRAs) that measure enhancer activity {de Almeida, Gosai, de Boer, White}. Once trained, these models can iteratively evaluate and optimize candidate sequences toward a predefined objective, such as maximizing activity in a specific cell type {Taskririn, Gosai}. More recently, generative modeling has been used to design synthetic enhancers, sampling sequences predicted to drive strong, context-specific gene expression {LegNet, regLM, DNA-diffusion}, albeit with limited experimental validation.

Despite the success of these models, the extent to which they are capable of learning more  complex enhancer grammars remains unclear. Interpretable machine learning methods {Novakovsky} have been used to show that models effectively identify binding sites for key transcription factors (TFs) required for tissue-specific activity and recognize common TFBS cooperativity patterns {de Almeida (both), BPNet, Gosai, Taskirin}. This information has been sufficient to predict enhancer activity in these contexts, but these models have yet to be sufficiently tested on enhancers that exhibit stronger syntax dependencies, where even small changes in motif order, spacing, or orientation can lead to drastic shifts in gene expression, including loss of specificity {Farley refs}. 

Many of these models are constrained by the relatively small number of higher-order TFBS combinations present in naturally occurring genomic sequences {refs, de Boer}. In contrast, MPRAs performed on synthetically designed sequences enable systematic interrogation of enhancer function with more control over TFBS composition and syntax {}. These assays break down enhancer complexity into targeted, testable components that are effective for isolating grammatical rules and revealing dependencies that may be difficult to infer from natural sequences {refs, King paper? Fromel?}.

Here, we present a systematic approach for learning the relationship between DNA sequence and function by combining deep experimental profiling of TFBS syntax with deep learning. 
We first define the necessary and sufficient TFBSs within an enhancer of interest that are used to construct a DNA sequence library where these TFBSs are systematically rearranged. 
We then characterize the regulatory activity of the library in vivo using MPRA and train a neural network to map TFBS syntax to function. 
We use interpretable machine learning methods to investigate how the model makes its predictions.
Finally, we use the trained model as an oracle to generate a library of synthetic enhancers with predicted tissue specificity and test these candidate sequences using both bulk and single-cell MPRA.
To illustrate this approach, we applied it to an enhancer controlling Otx-a expression in the developing Ciona robusta {REF} embryo. We tested over 921,600 sequences for function in vivo using MPRA, and trained an accurate model of enhancer function from TFBS syntax alone. We found that enhancer function in this screen can be decomposed into a primary additive model of TFBS combinations, … We found that X% of our synthetic enhancers are… and X% are tissue specific. This study demonstrates…


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{TFBS syntax drives enhancer activity in the neural plate of developing Ciona}

\subsection{TFBS syntax alone accurately predicts enhancer activity}

\subsection{Sirius learns a primarily additive model of TFBS syntax features}

\subsection{Sirius enables accurate tissue-specific enhancer design}

\subsection{Features beyond GATA/ETS syntax improve prediction of genomic enhancer function}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Materials and Methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Ciona}


\section{Data availability}

\section{Code availability}

\section{Data availability}
