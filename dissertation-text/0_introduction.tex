\begin{dissertationintroduction}
    
\setcounter{chapter}{0}

\label{chap:introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The genome and the central dogma of biology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In every human cell, nearly two meters of DNA are compacted into the nucleus, an organelle only a few micrometers wide. This molecule uses just four nucleotide monomers, adenine (A), cytosine (C), guanine (G), and thymine (T), to encode the instructions for building and regulating entire organisms. The efficiency of this system is one of the many modern marvels of molecular biology.

The classical framework for understanding how DNA-encoded information is used by a cell is the central dogma of molecular biology \cite{Crick1958-tb}. The central dogma describes a sequential flow of information in which DNA is first transcribed into RNA, then translated into protein. Proteins in turn carry out the structural, enzymatic, and regulatory functions necessary for every cell. While numerous exceptions and refinements to the central dogma have since been discovered \cite{UnknownUnknown-tl,Crick1970-lz}, the core concept continues to drive our understanding of molecular biology today.

However, this model alone is insufficient to explain a fundamental observation in genomics. The number of protein-coding genes does not scale with organismal complexity \cite{Levine2003-ra}. Humans, for example, have roughly 20,000 protein-coding genes, fewer than some plants \cite{Lian2024-mt} and not dramatically more than worms \cite{Hobert2013-gh} or flies \cite{Alberts2002-ib}. This suggests that biological complexity does not arise solely from an organism’s protein repertoire, but from when, where and how much those proteins are expressed. This selective expression of proteins is a concept termed gene regulation. The focus of this thesis is on the events prior to and including transcription, the process by which information encoded in DNA is copied into RNA. There are many known mechanisms of gene regulation in eukaryotes that occur post-transcription \cite{Zhao2017-hm,Keene2007-iy}, but they are beyond the scope of the work presented here.

This thesis explores the mechanisms and principles of gene regulation through the lens of predictive modeling. The remainder of this introduction provides an overview of the molecular mechanisms that govern transcriptional regulation, followed by a discussion of the computational tools that have emerged to model them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Next-generation sequencing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The development of high-throughput DNA sequencing enabled the regulatory genomics field to extend beyond classical genetics studies and now sits at the center of genomics research \cite{Rodriguez2023-yt}. Nearly every assay discussed in this thesis relies on next-generation sequencing (NGS) in some form. In brief, all of these assays convert a molecular signal, such as messenger RNA (mRNA) abundance or DNA-protein interactions, into quantifiable DNA fragments. These fragments are amplified and subjected to sequencing-by-synthesis (SBS), a process in which DNA polymerase incorporates labeled nucleotides one at a time while a camera simultaneously captures the identity of each base. Carried out in parallel for millions of DNA fragments, SBS enables sequencing of entire genomes in one experiment. By applying NGS across multiple cell types, developmental stages, or environmental conditions, researchers can uncover shared and context-specific mechanisms of interest.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mechanisms of transcriptional regulation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The regulation of transcription determines whether and how a gene is expressed in a given cell and is shaped by both the local DNA sequence and its broader chromatin environment.

\subsection{Chromatin Accessibility and Epigenomic Modifications}

In eukaryotic cells, DNA is tightly packaged into the nucleus. At the lowest level, \~147\,bp of DNA is wrapped around an octamer of histone proteins to form a nucleosome \cite{Klemm2019-iv}. This compaction both protects DNA and restricts its accessibility for interaction. Nucleosome occupancy and spacing vary across the genome. In many cell types, large regions of the genome are densely nucleosome-bound and transcriptionally inert, whereas expressed genes and regulatory elements, such as promoters \cite{Hartley2009-ab}, enhancers \cite{Levine2010-ry}, and insulators \cite{West2002-tz}, are typically depleted of nucleosomes. In this manner, nucleosome occupancy and spacing produce a continuum of chromatin states ranging from tightly compacted (termed heterochromatin) to permissive (termed euchromatin) \cite{Klemm2019-iv}. The result is a highly dynamic landscape of “chromatin accessibility” that reflects the regulatory state of the genome \cite{Meuleman2020-cc}.

Chromatin modifying enzymes play key roles in establishing and maintaining accessible or repressive chromatin states. For example, histone acetyltransferases (HATs) and histone deacetylases (HDACs) can respectively add or remove acetyl groups from histone tails, altering nucleosome stability and influencing transcriptional accessibility \cite{Eberharter2002-hm}. Similarly, histone methyltransferases (HMTs) and demethylases add or remove methyl groups at specific lysine residues on histones, with distinct consequences depending on the site and context. For instance, H3K4me3 is a histone mark enriched in actively transcribed promoters in eukaryotes, whereas H3K27me3 marks repressed chromatin \cite{Millan-Zambrano2022-pr}. DNA methyltransferases (DNMTs) similarly catalyze the addition of methyl groups to cytosines, often as a mechanism for longer-term gene silencing \cite{Moore2013-gr}. Such modifications, primarily observed on CpG dinucleotides, can act as recruitment signals for proteins, such as methyl-CpG binding domain (MBD) proteins, which further compact chromatin.

A number of high-throughput sequencing assays have been developed that profile chromatin accessibility genome-wide. These assays typically rely on the principle that regions of open chromatin are more susceptible to enzymatic activity than closed, nucleosome-bound regions. Among the earliest to be developed was DNase I hypersensitive site sequencing (DNase-seq). DNaseq-seq identifies accessible regions genome-wide by detecting preferential cleavage by DNase I \cite{Song2010-nn}. More recently, ATAC-seq (Assay for Transposase-Accessible Chromatin using sequencing) was developed with the benefits of low input requirements and scalability \cite{Buenrostro2013-lj}. In ATAC-seq, a hyperactive Tn5 transposase simultaneously cleaves accessible DNA and inserts sequencing adapters. The resulting fragments reflect nucleosome-free regions and can be sequenced via next-generation sequencing.

The most widely used technique to assess DNA methylation is Whole Genome Bisulfite Sequencing (WGBS) \cite{Cokus2008-jt}. In this approach, treatment of DNA with bisulfite converts unmethylated cytosines to uracils, which are read as thymines during sequencing. Although more costly and coverage-intensive than accessibility assays, WGBS provides a comprehensive view of the DNA methylation landscape.

\subsection{Transcription factor binding}

Transcription factors (TFs) are a diverse class of DNA-binding proteins that recognize and bind to short, degenerate DNA motifs \cite{Isbel2022-fj,Stormo2000-ei,Badis2009-hv}. Millions of transcription factor binding sites (TFBS) exist in the human genome, yet only a small subset is occupied in any particular cell type \cite{Spitz2012-la}. This discrepancy reflects the fact that TF binding is not determined by motif presence alone, but by a combination of factors including chromatin accessibility, local sequence context, and interactions with other TFs \cite{Shlyueva2014-nr}. The cellular concentration of a given TF also strongly influences which of its potential binding sites are occupied. The ability of a TF to bind to its motif is termed its binding affinity \cite{Stormo2010-xm}. High affinity sites may be bound even when TF concentration is low, whereas lower-affinity sites may only become occupied in high TF concentrations or when another neighboring motif is occupied (cooperation) \cite{Reiter2017-ru}. In this way, the interplay between cis-regulatory features (e.g., motif strength, spacing) and the trans-regulatory context (e.g., TF expression, co-factor availability) determines the overall pattern of TF binding and subsequent regulatory activity.

Transcription factor binding is most commonly measured using sequencing-based assays that capture protein–DNA interactions genome-wide. The canonical assay utilized is Chromatin Immunoprecipitation followed by sequencing (ChIP-seq) \cite{Johnson2007-pz}. In ChIP-seq, DNA-bound proteins are crosslinked to chromatin, fragmented, and immunoprecipitated using an antibody specific to the TF of interest. The co-precipitated DNA is then sequenced and aligned to the genome to identify binding sites. While ChIP-seq has been instrumental in mapping TF binding landscapes across cell types and conditions \cite{ENCODE_Project_Consortium2020-ns}, it has several limitations. These include relatively low resolution, dependence on high-quality antibodies, and the need for large amounts of input material \cite{Park2009-gj}. Moreover, crosslinking and sonication steps can introduce noise or bias in fragment recovery, complicating interpretation. To address these limitations, newer techniques such as CUT\&RUN (Cleavage Under Targets and Release Using Nuclease) and CUT\&Tag (Cleavage Under Targets and Tagmentation) have been developed \cite{Kaya-Okur2019-yz,Skene2017-vk}. These methods tether a fusion of protein A (or G) and micrococcal nuclease (or Tn5 transposase) to a target-specific antibody. Compared to ChIP-seq, these approaches offer higher signal-to-noise ratios, improved resolution, and compatibility with lower-input.

\subsection{Enhancers and cis-regulatory elements}

In many cases, multiple TFs bind in close proximity within a defined and accessible genomic region, forming a regulatory element that integrates these signals to activate gene expression \cite{Spitz2012-la}. These regions are known as enhancers and have been shown to control the precise patterns of gene expression required for successful development and homeostasis \cite{Levine2010-ry}. Putative enhancers harbor the majority of mutations associated with disease \cite{Zaugg2022-ar,Maurano2012-cg,Tak2015-km}, as single-nucleotide variants, insertions, or deletions within enhancer sequences can disrupt existing TFBSs, create novel ones, or alter the spatial organization of binding motifs \cite{Lim2024-ph,Zaugg2022-ar,noauthor_2023-va}. In some cases, genetic variation can also perturb enhancer–gene connectivity, altering which gene an enhancer regulates through changes in chromatin architecture \cite{Mortenson2024-tn}.

At a sequence level, enhancer function is mediated by the binding of transcription factors (TFs) to their cognate motifs, termed TF binding sites (TFBSs). This binding recruits the transcriptional machinery and activates gene expression \cite{Malik2023-sk}. Enhancer activity depends on a range of sequence features, including the type, number, and affinity of TFBSs, as well as their relative order, orientation, and spacing. Collectively, these features define the “grammar” of an enhancer \cite{Jindal2021-zk}. Additional factors such as local DNA shape, sequence context, and nucleosome positioning further modulate activity, with other unknown features likely. Enhancer grammar is discussed in more detail in Chapter 3 of this thesis.

Identifying enhancers in the genome remains a major challenge in regulatory genomics. Sequence conservation is often insufficient \cite{Farley2015-xx,noauthor_2023-un}, as many functional enhancers show little evolutionary constraint. Instead, epigenomic features are typically used to infer enhancer activity \cite{Shlyueva2014-nr}. These include chromatin accessibility, characteristic histone modifications such as H3K4me1 and H3K27ac, and binding by co-activator proteins like p300. While these markers are useful for nominating candidate enhancers, they provide correlative evidence rather than direct functional validation. This has motivated the development of high-throughput experimental approaches that test enhancer activity directly. One major class of such assays is the Massively Parallel Reporter Assay (MPRA) \cite{Inoue2015-yy,LeProust2010-nr}. In MPRAs, candidate enhancer sequences are cloned upstream (or downstream, in self-transcribing variants) of a minimal promoter driving a reporter gene, each tagged with a unique barcode. By sequencing the barcodes from transcribed RNA, the regulatory activity of each input sequence can be quantified in parallel. Several MPRA formats have been developed, including STARR-seq, in which candidate enhancers are cloned into the $3'$ untranslated region of the reporter transcript, allowing the enhancer itself to be directly transcribed and quantified \cite{Arnold2013-bk}. While MPRAs offer a powerful means of studying enhancer activity at scale, they are often performed in an episomal context outside of the element’s native chromatin. Recent improvements include integrated MPRA designs, in which candidate enhancers are inserted into defined genomic loci, restoring the native chromatin environment \cite{Inoue2017-hm}.

Complementary to MPRAs are CRISPR-based perturbation screens, which enable the study of enhancers in their genomic context \cite{Cong2013-ib,Mali2013-gw}. In these approaches, pooled libraries of guide RNAs target candidate regulatory regions for CRISPR interference (CRISPRi) \cite{Gasperini2019-bs} or CRISPR activation (CRISPRa) \cite{Chardon2024-jy}. These methods are often coupled with single-cell transcriptomics or phenotypic readouts to link enhancer perturbation to function.

\subsection{Chromatin conformation and long-range interactions}

While enhancers can activate transcription from a distance, their regulatory reach is constrained by the three-dimensional (3D) organization of the genome. DNA is not arranged linearly in the nucleus but is folded into a hierarchy of spatial structures that influence which regulatory elements can physically interact with their target genes \cite{Zheng2019-ld}. At the broadest scale, the genome is partitioned into A/B compartments, reflecting transcriptionally active (euchromatic) and inactive (heterochromatic) regions \cite{Dixon2012-rp}. Within these compartments, chromosomes are further organized into topologically associating domains (TADs). TADs are regions in which regulatory elements are more likely to interact \cite{Rodriguez-Carballo2017-lh} and are thought to restrict enhancer activity to genes within the same domain. At a finer scale, architectural proteins such as CTCF and cohesin \cite{Merkenschlager2016-hx} moderate DNA looping that connects specific enhancer–promoter pairs. These loops can form through a mechanism known as loop extrusion, wherein cohesin slides along DNA until it is halted by CTCFs bound in the proper orientation, bringing distal regulatory elements into physical proximity \cite{Fudenberg2017-wd}.

Genome-wide chromatin conformation can be profiled using chromosome conformation capture (3C) based techniques \cite{Lieberman-Aiden2009-tc}. Among these, Hi-C is the most widely used, providing genome-wide contact maps at varying resolutions depending on sequencing depth \cite{Belton2012-yi}. Variants such as Micro-C \cite{Hsieh2015-ao} and PLAC-seq \cite{Yu2021-nv} combine chromatin interaction profiling with nucleosome-level or protein-targeted resolution, enabling more precise assignment of enhancer–promoter interactions. These data are increasingly integrated with other regulatory modalities to inform models of gene regulation across spatial scales \cite{Pal2019-so}.

\subsection{Advances in single-cell assays for regulatory genomics}

The previously described assays have traditionally been performed on samples prepared in “bulk”, meaning that the assay measures an average signal across all cells included as input. While bulk functional assays have enabled genome-wide mapping of putative regulatory features \cite{ENCODE_Project_Consortium2020-ns}, they often obscure the cell-to-cell heterogeneity present within complex samples. Sorting cells based on known surface markers prior to profiling can partially address this issue, but is limited to well-characterized cell types and can miss rare or uncharacterized populations. This is particularly limiting for studying enhancers, which are often active only in specific cell types, developmental stages, or physiological conditions. 

To overcome the limitations of bulk profiling, a variety of  assays have been developed to measure key regulatory features, such as mRNA expression, chromatin accessibility, DNA methylation, and 3D genome organization, at single-cell resolution \cite{Preissl2022-mq}. Though technologies differ in how cells are isolated and barcoded, they often share a common strategy: tagging molecular fragments with cell-specific barcodes so that sequencing reads can be attributed to individual cells. The first single-cell assay profiled gene expression by sequencing reverse transcribed mRNA molecules, with subsequent iterations improving through-put and data quality \cite{Lafzi2018-jm}. Single cell epigenome profiling variants followed soon after, including single-cell ATAC-seq (scATAC-seq) for profiling accessible chromatin \cite{Buenrostro2015-ox}, scWGBS for single-cell DNA methylation profiling \cite{Farlik2015-hr}, and single cell HiC for mapping chromatin conformation \cite{Nagano2013-tq}. For more details on single cell epigenomics technology, we refer the reader to a comprehensive review \cite{Preissl2022-mq} of the subject.

While individual single-cell assays can provide insights into a given layer of gene regulation, many regulatory phenomena emerge from the integration of multiple modalities. This was first addressed by profiling each modality in separate aliquots from the same sample, then computationally matching cells or cell types for downstream analysis \cite{Argelaguet2021-ws}. This, however, obscures the cell-specific relationships between these layers and is subject to computational artifacts introduced in the data analysis. Paired multi-modal single-cell assays overcome these limitations by measuring multiple features within the same cell. For example, the 10x Genomics Multiome platform simultaneously captures chromatin accessibility and gene expression from the same nuclei. Similarly, snm3C-seq integrates DNA methylation and chromatin conformation by combining bisulfite conversion with 3C-like proximity ligation, allowing simultaneous measurement of epigenetic state and 3D genome structure in individual cells \cite{Liu2021-km,Lee2019-qo}. These technologies have opened the door to building more complete models of gene regulation from direct measurements of multiple modalities in individual cells.

Despite their utility, single-cell assays present substantial computational challenges \cite{Heumos2023-hq,Kharchenko2021-ba}. Most single-cell datasets are dominated by zeros as each cell typically yields a limited number of fragments, making it difficult to distinguish technical noise from true biological absence. This issue is especially pronounced in modalities like ATAC-seq and DNA methylation which measure biochemical activity genome-wide. A common strategy to mitigate sparsity is to aggregate information across similar cells, using clustering or nearest-neighbor smoothing \cite{Kiselev2019-ky}, enabling more robust downstream analyses.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Predictive models of transcriptional regulation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Disentangling the complexity of transcriptional regulation requires building computational models. I define models in this thesis as formal representations of functions that link molecular features, such as DNA sequence or chromatin state, to functional readouts like transcription factor binding, chromatin accessibility, or gene expression. Among the many ways to approach model building, one particularly powerful strategy is by predicting.

When models accurately predict observed functional readouts, they do more than simply reproduce the data. When properly interpreted, they can also reveal which features are informative and how they interact. In the remainder of this section, I introduce the predictive modeling framework known as supervised learning, and then focus on a class of supervised models that take DNA sequence as input and predict regulatory activity as output. These “sequence-to-function” models form the methodological backbone of this thesis \cite{Sasse2024-ly}.

\subsection{Learning by predicting: supervised models in regulatory genomics}

Supervised learning represents a class of learning algorithms whose goal is to learn a function that maps inputs to outputs based on a set of examples. Each example consists of an input (e.g., a DNA sequence, chromatin profile, or other molecular feature vector) and an associated target or label (e.g., transcription factor binding, chromatin accessibility, or gene expression). A supervised model is trained on many such input–output pairs, with algorithms that adjust model parameters to minimize the discrepancy between predictions and the observed labels. Once trained, the model can be evaluated on new, unseen inputs to assess how well it generalizes. This process enables the model to capture statistical relationships between molecular features and regulatory activity.

The performance and interpretability of a supervised model depend heavily on two key choices. The first, is what features are given to the model as input. In some cases, features are manually crafted from prior biological knowledge, such as motif matches, GC content, or epigenomic annotations. In others, raw inputs like DNA sequence are passed directly to the model, which then learns its own internal representation of the features. The second key choice is the learning algorithm. The structure of the model itself defines the types of functions it can learn and also shapes how we interpret its behavior. For instance, one could simply learn a single weight for each input feature and add up the weighted sum as a prediction. Such models that capture additive relationships between features and outputs are termed linear models. Linear models are very simple to interpret, but most relevant biological phenomena of interest are inherently non-linear and subject to a wide variety of interactions (e.g. an enhancer may only be active when a combination of TFs is bound). Non-linear models, such as decision trees \cite{Rokach2006-hf}, kernel methods \cite{Ghandi2014-hn,Hofmann2007-sl}, and neural networks, have additional capacity to learn more complex functions that include interactions between features. 

Among non-linear approaches, deep learning has emerged as a particularly powerful tool for modeling regulatory genomics data \cite{Eraslan2019-ye}. Deep neural networks (DNNs) are composed of many layers of interconnected nodes (or neurons), which enable them to learn hierarchical representations of input features directly from data \cite{LeCun2015-fx}. Unlike shallow models, which rely on fixed or manually chosen features, deep networks can learn relevant patterns by optimizing performance on a prediction task. Some of the earliest work in promoter recognition from sequence features involved neural networks \cite{Lukashin1989-wi,O-Neill1991-dh}. Recent advances in hardware, scalable software frameworks \cite{Paszke2019-fm}, and large functional genomics datasets have made them practical for widespread use in genomics.

As the use of deep learning to model genomics data has grown, so too has the need to understand what these models are actually learning. The capacity a model has for learning arbitrary functions makes neural network representations difficult to interpret by default. To address this, many methods have been developed to extract meaningful biological insight from trained models \cite{Novakovsky2022-ft,Shrikumar2017-og,Lundberg2017-hh,Talukder2021-wj,Koo2020-vz}. These approaches are essential for moving from predictive performance to mechanistic understanding and are explored in further detail in Chapter 2.

\subsection{Sequence-to-function models}

When the input to a supervised model is restricted to DNA sequence features alone, and the outputs correspond to functional genomic measurements, we refer to the model as a sequence-to-function model \cite{Sasse2024-ly}. When successful, this formulation produces a model that has learned features present in DNA that determine how the sequence is interpreted by cellular machinery.

There are many strategies for encoding DNA sequence as model input. Some models begin with manually crafted features derived from biological knowledge, such as motif match scores, GC content, or the presence of known transcription factor binding sites (TFBS) \cite{De_Boer2020-mw}. Other models rely on k-mer based representations of sequences, such as gapped k-mer support vector machines (gkm-SVMs), which offer a more agnostic view of sequence \cite{Ghandi2014-hn}. SVM based models, however, can be computationally intensive to train and typically do not match the expressive power of neural networks, which can also operate directly on sequence (e.g., using a one-hot encoding: A = [1,0,0,0], C = [0,1,0,0], etc.). 

Sequence-to-function models have been successfully applied to predict a broad range of regulatory readouts, including gene expression \cite{Linder2025-or}, TF binding \cite{Avsec2021-sw}, RNA protein binding \cite{Horlacher2022-ja}, chromatin accessibility \cite{Pampari2025-lm}, transcriptional activity \cite{De_Almeida2022-aa,Gosai2023-cw}, transcription initiation \cite{Cochran2024-ab}, and 3D genome organization \cite{Fudenberg2020-gs}. The way these output signals are represented is also critical to successful modeling. Early sequence-to-function models were often trained to perform binary classification, distinguishing high-signal “peak” regions from low-signal “background” regions \cite{Zhou2015-rk}. In contrast, MPRA-based models typically predict continuous regulatory activity, such as log fold-change or reporter signal \cite{De_Almeida2022-aa}. More recently, the field has adopted models that have predicted a “profile” of signal at base-pair resolution \cite{Schreiber2021-vf}. Across tasks, these models show improved performance and have enabled finer-grained interpretations \cite{Avsec2021-sw,Pampari2025-lm}.

\subsection{Applications}

One of the most compelling properties of training sequence-to-function models is that they naturally support the kinds of counterfactual reasoning that is most relevant to open questions in regulatory genomics. This capability enables three major classes of applications: 1) mechanism discovery, 2) sequence design, and 3) variant interpretation.

\textbf{Uncovering regulatory mechanisms} \cite{Toneyan2024-nt}: Even without variants, sequence-to-function models can be analyzed to understand how sequence features drive predicted function. By examining which features are consistently used across sequences and generating in silico perturbations to these, we can generate hypotheses about how these features logic govern the regulatory activity we measure. Methods for this application are discussed in Chapter 1 and applied in Chapters 2 and 3.

\textbf{Synthetic genomics and sequence design} \cite{De-Winter2025-nz}: When trained and evaluated properly, sequence-to-function models have great potential for the design of synthetic DNA sequences that optimize a desired outcome. In doing so, accurate models can reduce the experimental burden of large-scale screening and facilitate the design of synthetic sequences with tissue-specific or tunable activity. This application is the focus of Chapter 2.

\textbf{Variant interpretation} \cite{Dey2020-lf}: By comparing model predictions for a reference and alternative sequence (e.g. the reference sequence with a known disease causing mutation), we can estimate the functional effect of genetic variation on function. Using model interpretation tools \cite{Shrikumar2017-og}, we can also unpack how the variant alters sequence features learned by the model. This application is the focus of Chapter 3.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Aims and Scope of this thesis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This thesis explores how predictive models can be used to better understand and manipulate transcriptional regulation from the underlying DNA sequence. Its contributions are both methodological and biological. I develop unified tools for training and interpreting machine learning models in regulatory genomics, and apply these tools across two biological contexts to illustrate their utility. This thesis is broken down into three main chapters:

\textbf{Universal software for machine learning in regulatory genomics}

Chapter 1 describes a general-purpose software platform for training, evaluating and interpreting machine learning models in regulatory genomics. This platform standardizes common end-to-end data analysis workflows, enabling rapid development, interpretation, and reuse of sequence-to-function models.

\textbf{TFBS syntax-driven design of neural-specific enhancers in vivo}

Chapter 2 explores how TFBS syntax governs enhancer activity by developing a predictive model trained on a large-scale, synthetic MPRA. I use this model to identify TFBS organizational rules that underlie functional enhancers and to design synthetic enhancers with tissue-specific activity.

\textbf{Unraveling the sequence determinants of environment-induced changes in pancreatic beta-cell states}

Chapter 3 focuses on variant interpretation in pancreatic beta cells. Using single-cell multiomics data, I build sequence-to-accessibility models to quantify the impact of noncoding genetic variants on chromatin accessibility.

Together, these chapters highlight the importance of continuing to develop predictive modeling approaches in regulatory genomics and demonstrate how sequence-to-function models can be applied to better understand and manipulate transcription.

\end{dissertationintroduction}
