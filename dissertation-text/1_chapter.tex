\chapter{Universal software for machine learning in regulatory genomics}
\label{chap:chapter 1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Deep learning (DL) has become a popular tool to study cis-regulatory function. Yet, efforts to design software for DL analyses in regulatory genomics that are Findable, Accessible, Interoperable and Reusable (FAIR) have fallen short of fully meeting these criteria. Here, we present EUGENe (\textbf{E}lucidating the \textbf{U}tility of \textbf{G}enomic \textbf{E}lements with \textbf{Ne}ural Nets), a FAIR toolkit for the analysis of genomic sequences with DL. EUGENe consists of a set of modules and subpackages for executing the key functionality of a genomics DL workflow: 1) extracting, transforming and loading sequence data from many common file formats, 2) instantiating, initializing and training diverse model architectures, and 3) evaluating and interpreting model behavior. We designed EUGENe as a simple, flexible and extensible interface for streamlining and customizing end-to-end DL sequence analyses, and illustrate these principles through application of the toolkit to three predictive modeling tasks. We hope that EUGENe represents a springboard toward a collaborative ecosystem for DL applications in genomics research.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Cracking the cis-regulatory code that governs gene expression remains a fundamental challenge in genomics research. Efforts to annotate the genome with functional genomics data\cite{ENCODE_Project_Consortium2012-tn} have powered machine learning methods that aim to learn biologically relevant sequence features by directly predicting these readouts. Deep learning (DL) has become especially popular in this space, and has been successfully applied to tasks such as DNA and RNA protein binding motif detection\cite{Alipanahi2015-ef,Pan2018-of,Quang2019-gi,Koo2021-ly,Wang2018-ls}, chromatin state prediction\cite{Zhou2015-rk,Quang2016-ll,Kelley2016-oh,Kelley2018-if,Minnoye2020-vz,Atak2021-sz,Li2021-sb,Yuan2022-gg,Chen2022-bn,Janssens2022-vy,Nair2019-um,Ullah2021-th}, transcriptional activity prediction\cite{Kelley2018-if,Zhou2018-mt,Agarwal2020-os,Avsec2021-hh,Karbalayghareh2022-gt} and 3D contact prediction\cite{Fudenberg2020-gs,Zhou2022-mp,Yang2021-yq,Tan2023-ro}. Recently, complementary models have been developed to predict data from massively parallel reporter assays (MPRAs) that directly test the gene regulatory potential of selected sequences\cite{De_Almeida2022-aa,Movva2019-jo,Jores2021-iu}. Most encouragingly, many of these multilayered models go beyond state of the art (SOTA) predictive performance to generate expressive representations of the underlying sequence that can be interpreted to better understand the cis-regulatory code\cite{Avsec2021-sw,Janssens2022-vy,De_Almeida2022-aa}.

Despite these advances, executing a deep learning workflow in genomics remains a considerable challenge. Though model training has been substantially simplified by dedicated DL libraries such as PyTorch\cite{Paszke2019-fm} and Tensorflow\cite{Abadi2016-il}, nuances specific to genomics data create an especially high learning curve for performing analyses in this space. On top of this, the heterogeneity in implementations of most code associated with publications greatly hinders extensibility and reproducibility. These conditions often make the development of genomics DL workflows painfully slow even for experienced DL researchers and potentially inaccessible to many others.

Accordingly, the genomics DL community has assembled software packages\cite{Budach2018-va,Chen2019-dt,Kopp2020-fw,Avsec2019-ke,Chalupova2022-kv} that aim to address one or more of these challenges. However, each toolkit on its own does not offer both end-to-end functionality and simplicity, and there remains a general lack of interoperability between packages. For instance, Kipoi\cite{Avsec2019-ke} increases the accessibility of trained models and published architectures, but does not provide a comprehensive framework for an end-to-end DL workflow. Selene\cite{Chen2019-dt} implements a library based in PyTorch for applying the full DL workflow to new or existing models, but offers a limited programmatic interface, requires the use of complex configuration files, and has limited functionality for model interpretation. Janggu\cite{Kopp2020-fw}, one of the more comprehensive packages, provides extensive functionality for data loading and for training models, but offers limited support for PyTorch and limited functionality for model interpretation. 

Generally, there is a need for an end-to-end toolkit in this space that follows FAIR data and software principles\cite{Barker2022-on} and that is inherently designed to be simple and extensible. To address this need, we have developed EUGENe (\textbf{E}lucidating the \textbf{U}tility of \textbf{G}enomic \textbf{E}lements with \textbf{Ne}ural Nets), a FAIR toolkit for the analysis of sequence-based datasets.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The EUGENe workflow}

A standard EUGENe workflow consists of 3 main stages outlined in \textbf{Figure~\ref{fig:1 Figure 1}}: extracting, transforming and loading (collectively ETL) data from common file formats (\textbf{Figure~\ref{fig:1 Figure 1}a}), instantiating, initializing and training (collectively IIT) neural network architectures (\textbf{Figure~\ref{fig:1 Figure 1}b}), and evaluating and interpreting (EI) learned model behavior on held-out data (\textbf{Figure~\ref{fig:1 Figure 1}c}). The major goal of EUGENe is to streamline the end-to-end execution of these three stages to promote the effective design, implementation, validation and interpretation of DL solutions in regulatory genomics. We have listed several common DL for regulatory genomics tasks that can be implemented in an end-to-end fashion with EUGENe (\textbf{Supplementary Table 1}). We next describe three in detail, highlighting the core aspects of the workflow on different data types and training tasks. A more detailed description of the workflow is provided in the Methods section.

\clearpage

\thispagestyle{plain}
\noindent
\textbf{Figure~\ref{fig:1 Figure 1}. EUGENe workflow for predictive analyses of regulatory sequences}. The EUGENe workflow can be broken up into three primary stages: \textbf{a}, data extraction, transformation and loading (ETL), \textbf{b}, model instantiation, initialization and training (IIT), and \textbf{c}, model evaluation and interpretation (EI). The ETL stage (\textbf{a}) begins with using the SeqData subpackage to create Dask enhanced, XArray datasets backed by Zarr stores. Data transformation is handled by the SeqPro subpackage, after which data can be loaded into graphical processing units (GPUs). In the subsequent IIT stage (\textbf{b}), model architectures (such as the example shown in the schematic) are instantiated from configuration files (in YAML format) from the EUGENe application programming interface (API) or from Kipoi. EUGENe then uses PyTorch Lightning for training these architectures. The subpackage SeqExplainer (which is backed by the Captum package) is used for model interpretation in the EI stage (\textbf{c}). Common visualizations produced by SeqExplainer include the logos depicted for an example input sequence (top) or for convolutional filters (bottom).

\clearpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=0.8\textheight, keepaspectratio]{1_figures-and-files/figure1.png}
    \caption[EUGENe workflow for predictive analyses of regulatory sequences]{\textbf{EUGENe workflow for predictive analyses of regulatory sequences}.}
    \label{fig:1 Figure 1}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{STARR-seq plant promoter activity prediction}

We first used EUGENe to analyze published data from an assay of plant promoters\cite{Jores2021-iu} (\textbf{Figure~\ref{fig:1 Figure 2}a}). Jores et al selected promoter sequences from -165 to +5-bp relative to the annotated transcription start site (TSS) for protein-coding and microRNA (miRNA) genes of \textit{Arabidopsis thaliana}, \textit{Zea mays} (maize), and \textit{Sorghum bicolor}. A total of 79,838 170-bp promoters were used to transiently transform two separate plant systems, tobacco leaves and maize protoplasts. Regulatory activity was quantified using a variant of the self-transcribing active regulatory region sequencing (STARR-seq) assay\cite{Jores2020-hm} in each system. The resulting data provides two activity scores that can serve as single task regression targets for training EUGENe models.

We implemented both the custom BiConv1D layer\cite{Onimaru2020-do} and CNN architecture (Jores21CNN) described in Jores et al, and then trained separate Jores21CNN architectures for predicting tobacco leaf (leaf models) and maize protoplast (protoplast models) activity scores. We benchmarked these models against built-in CNN and Hybrid architectures with matched hyperparameters, as well as a DeepSTARR architecture\cite{De_Almeida2022-aa} (\textbf{Supplementary Data 1}). As described in Jores et al (see Methods), we initialized 78 filters of the first convolutional layer of all models with position weight matrices (PWMs) of plant transcription factors (n=72) and core promoter elements (n=6)\cite{Jores2021-iu}. In both systems, performance metrics for the most predictive models were comparable to those reported in Jores et al (\textbf{Figure~\ref{fig:1 Figure 2}b}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_1}a}). We also trained models on activity scores from both leaves and protoplasts (combined models) and noted a marked drop in performance (\textbf{Supplementary Figure~\ref{fig:1 supplementary_1}b}), underscoring differences in the way the leaf and maize systems interact with the same set of promoters\cite{Jores2021-iu}.

We next applied several of EUGENe’s interpretation functions to the trained models to determine the sequence features each used to predict plant promoter activity. First, we used a filter visualization approach\cite{Minnoye2020-vz} to generate position frequency matrix (PFM) representations for each of the first convolutional layer’s filters and applied the TomTom\cite{Gupta2007-zw} tool to annotate them. We queried the PFMs against the 78 motifs used to initialize the convolutional layers, both to determine if the initialized filters retained their motifs and to see if randomly initialized filters learned them de novo. For the leaf and protoplast models, many of the learned filters were annotated to the TATA box binding motif and other core promoter elements (\textbf{Figure~\ref{fig:1 Figure 2}c}\textbf{d}). Only 10 learned filters from the combined model were assigned a significant annotation by TomTom (\textbf{Figure~\ref{fig:1 Figure 2}d}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_1}c}), consistent with the observed performance drop in this system (\textbf{Supplementary Figure~\ref{fig:1 supplementary_1}a}). Next, we applied the DeepLIFT method\cite{Shrikumar2016-lf} to determine the individual nucleotide contributions for each test set sequence prediction. For many of the sequences with the highest observed activity scores, the TATA box motifs were often the lone salient feature identified (\textbf{Figure~\ref{fig:1 Figure 2}e}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_1}d}). In fact, when only a TATA box motif was inserted into every possible position in each of 310 selected promoters, we observed a 147\% average increase in predicted activity across insertion positions and sequence contexts for the leaf model (\textbf{Figure~\ref{fig:1 Figure 2}f}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_1}e}). Finally, we performed 10 rounds of in silico evolution on the same set of 310 promoters as described in Jores et al. Almost all starting promoters showed a significant increase in predicted activity after just three mutations (\textbf{Figure~\ref{fig:1 Figure 2}g}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_1}f}). These results showcase a representative example of the way EUGENe’s interpretation suite can be used to identify the key features that a model uses to make predictions.

\clearpage

\thispagestyle{plain}
\noindent 
\textbf{Figure~\ref{fig:1 Figure 2}. STARR-seq plant promoter activity prediction}. \textbf{a}, jores21 use case schematic. We trained EUGENe models to predict the regulatory activity of 79,838 plant promoters quantified by plant STARR-seq in tobacco and maize. \textbf{b}, Performance comparison of four convolution-based architectures on predicting promoter activity in tobacco leaves (left) and maize protoplasts (right). The boxplots show distributions of R\textsuperscript{2} values on held-out test data for each architecture across \(n = 5\) independent experiments (random initializations). The boxes show medians along with low and high quartiles. Whiskers extend to the furthest datapoint within 1.5 times the interquartile range. More extreme points are marked as outliers. A two-sided Mann-Whitney U test was used to determine p-values which were adjusted by the Benjamini-Hochberg method (* = \(p < 0.05\), ns = not significant). Test statistics and adjusted p-values for the leaf models (left) were: CNN-Hybrid (\(u=15\), adjusted \(p=0.01\)), CNN-DeepSTARR (\(u=24\), adjusted \(p=0.17\)), CNN-Jores21CNN (\(u=12\), adjusted \(p=1.0\)), Hybrid-DeepSTARR (\(u=17\), adjusted \(p=1.0\)), Hybrid-Jores21CNN (\(u=22\), adjusted \(p=1.0\)), DeepSTARR-Jores21CNN (\(u=14\), adjusted \(p=0.84\)). Test statistics and adjusted p-values for the protoplast models (right) were: CNN-Hybrid (\(u=15\), adjusted \(p=0.03\)), CNN-DeepSTARR (\(u=24\), adjusted \(p=0.01\)), CNN-Jores21CNN (\(u=12\), adjusted \(p=0.01\)), Hybrid-DeepSTARR (\(u=17\), adjusted \(p=0.01\)), Hybrid-Jores21CNN (\(u=22\), adjusted \(p=0.01\)), DeepSTARR-Jores21CNN (\(u=14\), adjusted \(p=0.01\)). \textbf{c}, A hand selected set of convolutional filters visualized as PWM logos that had significant annotations to known core promoter elements (CPE) and transcription factor (TF) binding clusters in plants. \textbf{d}, Histogram showing the number of learned filters assigned to CPEs and TF binding clusters by TomTom with bolded annotations corresponding to the logos in \textbf{c}. \textbf{e}, Sequence logo visualizations of feature importance scores calculated using the DeepLIFT algorithm on the highest predicted test set sequence in the Hybrid leaf (top) and Jores21CNN protoplast (bottom) model. \textbf{f}, Model scores for \(n=310\) sequences implanted with a 16bp sequence containing a consensus TATA box motif, a shuffled version of the same sequence, an all-zeros sequence, and a random sequence (all 16bp in length). Mean model scores with 95\% confidence intervals are shown. \textbf{g}, Model scores for the same set of \(n=310\) promoters at different rounds of evolution compared against baseline predictions (evolution round 0). The best Hybrid leaf model was used to generate panels \textbf{c}, \textbf{d}, \textbf{f}, and \textbf{g} (protoplast model results are shown in Supplementary Figure~1). Source data are provided in the \texttt{Figure2\_SourceData.zip} file.

\clearpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=0.8\textheight, keepaspectratio]{1_figures-and-files/figure2.png}
    \caption[STARR-seq plant promoter activity prediction]{\textbf{STARR-seq plant promoter activity prediction}.}
    \label{fig:1 Figure 2}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{\textit{In vitro} RNA binding prediction with DeepBind}

To illustrate EUGENe’s versatility for different inputs and prediction tasks, we next applied it to analyze RNA binding protein (RBP) specificity data introduced in Ray et al\cite{Ray2013-yd} and analyzed with DL in Alipanahi et al\cite{Alipanahi2015-ef}. In the latter work, they trained 244 CNN models (DeepBind models) that each predicted the binding patterns of a single RBP on a set of 241,357 RNA probes (\textbf{Figure~\ref{fig:1 Figure 3}a}). The full probe set was designed to capture all possible RNA 9-mers at least 16 times and was split into two balanced subsets, Set A and Set B, for training and validation respectively (see Methods)\cite{Ray2013-yd}. Each RBP was incubated with a molecular excess of probes from each subset (in separate experiments) and subsequently recovered by affinity purification. The RNAs associated with each RBP were then quantified by microarray and subsequent bioinformatic analysis\cite{Berger2009-la}. This yielded a vector of continuous binding intensity values for each RBP across the probe set that can be used for prediction.

To prepare for training, we first implemented a flexible DeepBind architecture in EUGENe (see Methods), and then trained 244 single task models using a nearly identical training procedure to Alipanahi et al. (\textbf{Supplementary Data 2}). Along with these single task models, we also randomly initialized and trained a multitask model (\textbf{Supplementary Data 2}) to predict 233 RBP specificities (i.e. a 233 dimensional vector) in a single forward pass, excluding 11 RBPs due to a high proportion of missing values across probes in the training set. We also loaded 89 existing Kipoi\cite{Avsec2019-ke} models trained on a subset of human RBPs in the dataset.

Performance on Set B for all deep learning models was on par with Set B’s correlation to Set A (\textbf{Figure~\ref{fig:1 Figure 3}b}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}a}) and both single task and multitask models trained with EUGENe showed comparable performance to Kipoi and DeepBind models (\textbf{Figure~\ref{fig:1 Figure 3}b}\textbf{c}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}a}\textbf{b}). The reason for the poor observed performance of certain Kipoi models is not immediately clear, but could relate to differences in sequence or target preprocessing prior to evaluation. Though the ability to load these pretrained models from Kipoi is very useful for benchmarking, implementing and retraining models is often necessary for fair comparisons of performance. EUGENe supports both loading and retraining models, allowing users to more quickly design and execute quality benchmarking experiments. 

We next applied EUGENe’s interpretation suite to our trained models, first using the filter visualization approach outlined in Alipanahi et al to generate PFMs for convolutional filters. We again used TomTom to identify filters annotated with canonical RBP motifs\cite{Ray2013-yd} in both the best performing single task models and the multitask model (\textbf{Figure~\ref{fig:1 Figure 3}d}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}c}) and found that the number of multitask filters annotated to an RBP was correlated with predictive performance for that RBP (\textbf{Figure~\ref{fig:1 Figure 3}d}, bottom). We also calculated attributions for all Set B sequences using the InputXGradient method\cite{Shrikumar2016-lf} and observed that canonical motifs were learned by both single task and multitask models (\textbf{Figure~\ref{fig:1 Figure 3}e}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}d}). Finally, we used EUGENe’s sequence evolution functionality to evolve 10 random sequences using the single task HNRNPA1L2 model and visualized the attributions for these sequences before and after five rounds of evolution (\textbf{Figure~\ref{fig:1 Figure 3}f}). Several of the mutations that most increased the predicted score were those that generated canonical binding motifs for the protein. We repeated this for two other RBPs (Pcbp2 and NCU02404) and observed that each model prioritizes mutations that create canonical binding motifs specific to the RBP they were trained on (\textbf{Supplementary Figure~\ref{fig:1 supplementary_2}e}). These results show that EUGENe simplifies the extraction of salient features from models trained within the same workflow.

\clearpage

\thispagestyle{plain}
\noindent
\textbf{Figure~\ref{fig:1 Figure 3}. In vitro RNA binding prediction with DeepBind}. \textbf{a}, ray13 use case schematic. n=244 RNA binding proteins (RBPs) were assayed across a set of 241,357 RNA probes to generate a 241,357 x 244 dimensional matrix of normalized intensity values. \textbf{b}, Pearson correlations across four different metrics with each metric calculated from comparisons between observed (Set B) and predicted binding intensities (see Methods for more details on how each metric is calculated). Each boxplot indicates a distribution of Pearson correlations across all n=244 RBPs, except for Kipoi which includes n=89 RBPs. Ray et al, MatrixREDUCE, DeepBind and Observed intensities refer to correlations calculated from predicted intensities reported in Alipanahi et al. Observed intensities and SetA refer to correlations calculated using the intensities from Set A probes as the predicted intensities (see Methods). The boxes show medians along with low and high quartiles. Whiskers extend to the furthest datapoint within 1.5 times the interquartile range. \textbf{c}, Performance comparison scatterplots for ST models against MT models (left) and against Kipoi models (right). Each dot indicates a comparison of the Pearson correlation between predicted and observed intensities for two models on a single RBP. \textbf{d}, (top) A multitask filter with a TomTom significant annotation for HNRNPA1L2 visualized as a PWM logo. (middle) A filter for the single task HNRNPA1L2 model with a significant TomTom annotation for HNRNPA1L2. (bottom) The relationship between multitask performance (using the Z-scored Pearson correlations of observed and predicted intensities) on the y-axis, against the number of filters that were annotated with the corresponding RBP for that task on the x-axis. The Spearman’s correlation coefficient and associated p-value are shown. \textbf{e}, Attributions for the sequence with the highest observed intensity in the test set for HNRNPA1L2. The attributions were calculated using InputXGradient for single task (top) and multitask (bottom) models. \textbf{f}, The InputXGradient attribution scores for a random (top) and evolved (bottom) sequence after evolution with the HNRNPA1L2 single task model. Red dashed lines indicate mutations made during evolution and are annotated with the round the mutation occurred in. Source data are provided in the ExtendedFigure1\_SourceData.zip file.

\clearpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=0.8\textheight, keepaspectratio]{1_figures-and-files/extended_data_figure1.png}
    \caption[In vitro RNA binding prediction with DeepBind]{\textbf{In vitro RNA binding prediction with DeepBind}.}
    \label{fig:1 Figure 3}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{JunD ChIP-seq binding classification}

As our final use case, we applied EUGENe to the classification of JunD binding as described in Kopp et al\cite{Kopp2020-fw}. This task utilizes ChIP-seq data from ENCODE\cite{ENCODE_Project_Consortium2012-tn} to generate input sequences and binarized classification labels for each sequence (\textbf{Figure~\ref{fig:1 Figure 4}a}). We used EUGENe to first build a DL-ready dataset for this prediction task (see Methods), then implemented the CNN architecture described in Kopp et al (Kopp21CNN). We benchmarked classification performance against built-in FCNs, CNNs, and Hybrid models with matched hyperparameters (\textbf{Supplementary Data 3}). All built-in models were configured to incorporate information from both the forward and reverse strand (double stranded or “ds” models). 

We trained models using the same procedure described in Kopp et al (see Methods)\cite{Kopp2020-fw}. Due to the unbalanced nature of the dataset, we focused on evaluating models with the area under the precision recall curve (auPRC). For our Kopp21CNNs, we were able to achieve comparable performances on held out chromosome 3 sequences to those reported by Kopp et al for one-hot encoded sequences (\textbf{Figure~\ref{fig:1 Figure 4}b}\textbf{c}). The dsFCN, the only model without any convolutional layers, immediately overfit the data after a single training epoch and was not predictive of binding (\textbf{Figure~\ref{fig:1 Figure 4}c}). The dsCNN models, however, achieved higher mean auPRCs than dsHybrid models, and significantly higher auPRCs than Kopp21CNN architectures.

We next applied EUGENe’s interpretation tools to ask whether our best models were learning sequence features relevant to JunD binding to make predictions. We first generated attributions for the forward and reverse complement strands of all test set sequences using the GradientSHAP\cite{Lundberg2017-hh} method and visualized the most highly predicted sequences as sequence logos (\textbf{Figure~\ref{fig:1 Figure 4}d}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_3}a}). We observed that the most important nucleotides often highlighted consensus or near consensus JunD motifs and that these motifs were often attributed similarly on both the forward and reverse strands (\textbf{Figure~\ref{fig:1 Figure 4}d}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_3}a}). However, there were instances where salient motifs were highlighted on one strand but not the other (\textbf{Figure~\ref{fig:1 Figure 4}d}), indicating the utility of incorporating information from both strands for prediction. We next generated PFM representations for all 10 filters of each convolutional model (excluding dsFCNs) and annotated them using TomTom against the HOCOMOCO FULL v11 database\cite{Kulakovskiy2018-oz} (\textbf{Figure~\ref{fig:1 Figure 4}e}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_3}b}). Among the top hits, we found several filters annotated with motifs such as JunD and CTCF (\textbf{Figure~\ref{fig:1 Figure 4}e}, \textbf{Supplementary Figure~\ref{fig:1 supplementary_3}b}). Finally, we performed an in silico experiment with the best overall model where we slid a consensus JunD motif across each position of a set of 10 randomly generated sequences and predicted binding (\textbf{Figure~\ref{fig:1 Figure 4}f}). We observed that the simple inclusion of the consensus binding site led to a significant jump in predicted output with some position specificity. These results once again showcase that EUGENe’s interpretation methods can help explain model predictions, in this case for DNA protein binding from a genome wide assay.

\clearpage

\thispagestyle{plain}
\noindent
\textbf{Figure~\ref{fig:1 Figure 4} JunD ChIP-seq binding classification}. \textbf{a}, kopp21 use case schematic. We used SeqData to load in a set of 11,086 ChIP-seq peaks for JunD and to generate positive and negative sets for JunD binding prediction. SeqData uses a set of regions of interest (ROIs) along with peaks and a bin size and outputs a set of labeled sequences for each bin in the ROI. Bins are labeled as positive (1) if they overlap a peak and negative (0) if they do not. Upon loading, each sequence is extended by 150bp in each direction to provide more sequence context for prediction. \textbf{b}, \textbf{c}, auPRCs on held-out test data from chromosome 3 for JunD binding classification across four double-stranded architectures \textbf{b}, The boxplots show distributions of auPRC values on held-out test data for each architecture across n=5 independent experiments (random initializations). A two-sided Mann-Whitney U test was used to determine p-values which were adjusted by the Benjamini-Hochberg method  (* = p < 0.05, ns = not significant). Test statistics and adjusted p-values were: dsFCN-Kopp21CNN (u=0, adjusted p-value=0.02), dsFCN-dsHybrid (u=0, adjusted p-value=0.02), dsFCN-dsCNN (u=0, adjusted p-value=0.02), Kopp21CNN-dsHybrid (u=4, adjusted p-value=0.11), Kopp21CNN-dsCNN (u=4, adjusted p-value=0.11), dsHybrid-dsCNN (u=8, adjusted p-value=0.42). \textbf{c}, auPR curves for the best models from each architecture. \textbf{d}, Sequence logos of attributions for the top predicted sequence. The top row shows attributions from the forward strand and the bottom row from the reverse strand. Attributions were calculated using GradientSHAP. \textbf{e}, A selected set of convolutional filters visualized as PWM logos with significant annotations from TomTom. \textbf{f}, Model scores for n=10 random sequences with consensus JunD motif implanted at each possible location. Mean model scores with 95\% confidence intervals are shown. The boxplot shows the distribution of scores for the random sequences prior to JunD motif implantation. All boxes show medians along with low and high quartiles. Whiskers extend to the furthest datapoint within 1.5 times the interquartile range. More extreme points are marked as outliers. Source data are provided in the ExtendedFigure2\_SourceData.zip file.

\clearpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=0.8\textheight, keepaspectratio]{1_figures-and-files/extended_data_figure2.png}
    \caption[JunD ChIP-seq binding classification]{\textbf{JunD ChIP-seq binding classification}.}
    \label{fig:1 Figure 4}
\end{figure}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

There are numerous opportunities for future development of EUGENe, but we see a few as high priority. EUGENe is primarily designed to work on nucleotide sequence input (DNA and RNA), but currently does not have dedicated functions for handling protein sequence or multi-modal inputs. Furthermore, as assays move from bulk to single cell resolution, it will be important to develop functionality for handling single cell data that allows users to easily ask questions about cell type specific regulatory syntax. Finally, we plan on expanding EUGENe’s dataset and model library to encompass a larger portion of those available in the field.

The heterogeneity in data types and methods that exist in DL for regulatory genomics and the rapid pace with which the field advances makes maintaining FAIR software in this space a major challenge. One of the tasks in \textbf{Supplementary Table 1}, for instance, involves a recently developed and highly specific data formatting and preprocessing pipeline\cite{Bravo_Gonzalez-Blas2019-fq}. The use of bespoke methods for data preprocessing, as well as for model interpretation, is quite common in the field, and is often necessary to train accurate models that avoid common machine learning pitfalls\cite{Whalen2021-fh}. For example, some workflows may require complex implementations of train and test set splitting to protect against information leakage\cite{Urban2020-ij}. We see substantial value in continuing to extend EUGENe into spaces such as these, and have designed the toolkit to allow for easy integration of this type of functionality. To continue to make bespoke methods and workflows accessible, we intend to encourage community development of EUGENe through tutorials, workshops and a dedicated user-group.

As large consortia (such as ENCODE Phase 4 and Impact of Genomic Variation on Function) and individual groups continue to generate functional genomics data at both the bulk and single cell level, the need for a standardized DL analysis ecosystem to investigate complex relationships in this data becomes even more pressing. We believe that EUGENe represents a positive step in the direction of such an ecosystem and will empower computational scientists to rapidly expand their knowledge, develop and share methods and models, and answer important questions about the genome and how it encodes function.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methods}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{plain}
\noindent
\textbf{Figure~\ref{fig:1 Figure 5}. End-to-end data processing, training, and interpretation with EUGENe}. \textbf{a}, SeqData objects can be loaded from files already on disk, or by calling for a dataset available for download from the SeqDatasets subpackage. Once instantiated, SeqData objects containerize the EUGENe workflow, easing the \textbf{b}, preprocessing of sequences and of sequence metadata, \textbf{c}, the generation of exploratory data analysis plots, and \textbf{d}, the creation of PyTorch loadable datasets and objects. \textbf{e}, An architecture can be instantiated either from a single function call (top) or from a configuration file (bottom). Conv1DBlocks and DenseBlocks both allow for flexibility in the ordering of layers they contain (one example ordering is shown). Instantiated architectures can be \textbf{f}, initialized with a desired initialization scheme, then \textbf{g}, fit to training data and used to predict on held-out data. Performance metric training curves are pictured in the top panel of \textbf{g}, test set performance curves for regression (left) and classification (right) are depicted in the bottom panel of \textbf{g}. Both training and prediction are handled by PyTorch Lightning. We show an example of the arguments for instantiating a SequenceModule in \textbf{h}. \textbf{i}, For filter interpretation, filters in the first convolutional layer are used to scan input sequences for “maximally activating subsequences” that can then be used to generate position frequency matrices and sequence logos. \textbf{j}, Attribution analysis starts by passing inputs sequences through the model to generate an output. This output signal is then backpropagated to the input to generate a per nucleotide score that can be visualized as a sequence logo. \textbf{k}, Random or synthetically designed sequences that have been mutated or have had motifs implanted in them can be scored using a trained model. Results from toy examples of this in silico approach are shown in \textbf{l} and \textbf{m}, which depict a positional importance analysis and a prediction evolution analysis respectively. Example function arguments have been omitted for \textbf{a}, \textbf{b}, \textbf{e}, \textbf{i}, \textbf{j}, \textbf{k}, \textbf{l} and \textbf{m}.

\clearpage

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=0.8\textheight, keepaspectratio]{1_figures-and-files/extended_data_figure3.png}
    \caption[End-to-end data processing, training, and interpretation with EUGENe]{\textbf{End-to-end data processing, training, and interpretation with EUGENe}.}
    \label{fig:1 Figure 5}
\end{figure}

\clearpage

\subsection{The EUGENe workflow}

\subsubsection{Data extraction, transformation and loading with SeqData}

The EUGENe workflow begins with extracting data from on-disk formats. Though standardized file formats exist in regulatory genomics, their complexity can make creating model-ready datasets non-trivial. To address this in EUGENe, we created the standalone subpackage SeqData (https://github.com/ML4GLand/SeqData) which flexibly and efficiently reads data from a variety of file formats, including CSV/TSV (tabular), FASTA, BED, BAM, and BigWig (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{a}}, top). The versatility of SeqData enables the generation of many custom datasets from combinations of these file types, including several commonly utilized in regulatory genomics. These include datasets derived from combinations of tabular and FASTA files that are suitable for single and multi-task regression and classification (e.g. DeepSTARR\cite{De_Almeida2022-aa}), datasets from genomic coordinates defined in BED files suitable for multi-task binary classification (e.g. DeepSEA\cite{Zhou2015-rk} or Sei\cite{Chen2022-bn}), and datasets from multiple BigWigs and BED files suitable for binned or base-pair resolution regression (e.g. Basenji\cite{Kelley2018-if} and BPNet\cite{Avsec2021-sw} respectively). EUGENe also supplies a growing collection of hand-curated datasets available via the SeqDatasets subpackage (https://github.com/ML4GLand/SeqDatasets) (\textbf{\textbf{Supplementary Data~4}}) that can be downloaded and subsequently loaded into a workflow via a single function call (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{a}}, bottom).

By default, SeqData reads files from disk as XArray datasets\cite{Hoyer2017-jv} backed by Zarr stores\cite{Miles2023-zk} (\textbf{Figure~\ref{fig:1 Figure 1}\textbf{a}}). We chose to use XArray and Zarr as they are scalable, capable of handling high dimensional data, and have been previously utilized in a variety of bioinformatics domains\cite{Baker2023-sp,Marconato2023-kz,Liu2021-km}. Furthermore, Zarr stores can be loaded out-of-core thanks to functionality offered by XArray and Dask\cite{Team2016-qa}, allowing for processing and training of large-scale datasets (\textbf{Supplementary Figure~\ref{fig:1 supplementary_4}\textbf{a}}). As is standard in DL, training in EUGENe is always done by loading data into GPU memory in batches (when a GPU is available), but is slowed by using the out-of-core functionality on the CPU (\textbf{Supplementary Figure~\ref{fig:1 supplementary_4}\textbf{b}}). Thus, the decision on whether to first load the dataset into CPU memory prior to training should balance available resources and dataset size. Certain datasets, such as those used to train Enformer\cite{Avsec2021-hh} or Basenji\cite{Kelley2018-if}, will likely require this out-of-core functionality. However, we have found that many useful and large datasets can entirely fit into memory on machines with less than 32GB of RAM (\textbf{\textbf{Supplementary Data~5}}).

Once created, an array of functions can be called directly on these XArray datasets to perform common preprocessing steps. EUGENe includes a baseline set of functions for train and test set splitting (e.g. by chromosome, fraction, or homology\cite{Teufel2023-kn}) and target normalization (e.g. binning, z-score, clamping, etc.) (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{b}}, left). Sequence preprocessing is handled by the SeqPro subpackage (https://github.com/ML4GLand/SeqPro), which includes Numba accelerated\cite{Lam2015-mo} padding and one-hot encoding of DNA and RNA sequences (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{b}}, right), as well as jittering and k-mer frequency preserving shuffling\cite{Jiang2008-li}. EUGENe also fully supports data visualization through the Matplotlib\cite{Hunter2007-es} and Seaborn\cite{Waskom2021-lk} libraries (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{c}}) and conversion of XArray datasets to formats ingestible by deep learning frameworks in a highly flexible manner (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{d}}). Finally, XArray datasets can easily be converted to more familiar Python data structures (NumPy arrays, Pandas DataFrames, etc.) and back to enable the user to access the functionality of these libraries.

\subsubsection{Model training with PyTorch and PyTorch Lightning}

Designing and training neural networks for regulatory genomics requires a comprehensive library of architecture building blocks. EUGENe builds on the PyTorch library of neural network layers by adding several useful layers such as inception and residual layers. Additionally, EUGENe provides flexible functions for instantiating common "blocks" and "towers" that are composed of heterogeneous sets of layers arranged in a predefined or adaptable order. For instance, a convolutional block (Conv1DBlock in EUGENe) often comprises convolutional, normalization, activation, and dropout layers in different orderings depending on the model and task (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{e}}, top). On top of this, EUGENe’s library supports customizable fully connected (FCN), convolutional (CNN), recurrent (RNN) and hybrid (a combination of the three, shown in \textbf{Figure~\ref{fig:1 Figure 1}\textbf{b}}) architectures that can be instantiated from single function calls or from configuration files (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{e}}, bottom and \textbf{\textbf{Supplementary Data~6}}, basic architectures). We have also constructed several published architectures that represent specific configurations of these basic architectures, and made them accessible to users through single function calls (\textbf{\textbf{Supplementary Data~6}}). Users looking to use their own custom architectures can also do so, as EUGENe only requires that an architecture be defined by its layers and how inputs are propagated through those layers (\textbf{Supplementary Figure~\ref{fig:1 supplementary_5}\textbf{b}}). In summary, model architectures can be instantiated from the API, built from scratch using our library, or imported from external repositories or packages. We provide a detailed tutorial on instantiating architectures via these different mechanisms in EUGENe’s tutorials repository (\url{https://github.com/ML4GLand/tutorials/blob/main/eugene/models/instantiating_models.ipynb}).

Once instantiated, architectures can be initialized with parameters sampled from standard initialization distributions (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{f}}, top), or in the special case of convolutional filters, initialized with known motifs\cite{Quang2016-ll,Janssens2022-vy} (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{f}}, bottom). EUGENe can then be used to fit initialized architectures to datasets (with the option to perform hyperparameter optimization through the RayTune package\cite{Moritz2017-tm}) and to assess performance and generalizability on held-out test data (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{g}}). For training, EUGENe uses the PyTorch Lightning (PL) framework\cite{Falcon2020-zq} and programmatic objects called LightningModules. Each EUGENe LightningModule delineates the architecture types it can train and standardizes boilerplate tasks for those architectures (e.g. optimizer configuration, metric logging, etc.). For instance, the primary LightningModule in EUGENe, termed SequenceModule (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{h}}), anticipates training an architecture that takes in a single tensor (typically one-hot encoded DNA sequences) and delivers a single tensor output. We have also implemented a ProfileModule for BPNet-style\cite{Avsec2021-sw} training, where models produce multiple tensor outputs (or “heads”), accept optional control inputs, and use multiple loss functions (\url{https://github.com/ML4GLand/use_cases/blob/main/BPNet/train_eugene.ipynb}). Using LightningModules in this manner requires only minor code modifications to allow for the reuse of the same architectures in different training schemes and tasks (\textbf{Supplementary Figure~\ref{fig:1 supplementary_5}\textbf{b}}) and for the fine-tuning of pretrained models (\textbf{Supplementary Figure~\ref{fig:1 supplementary_5}\textbf{c}}). We plan on continuing to develop the library of LightningModules for different training schemes, including adversarial learning\cite{Koo2019-dw}, generative modeling\cite{Taskiran2022-zj}, language modeling\cite{Ji2021-mj}, and more.

\subsubsection{Model interpretation with SeqExplainer}

Interpreting models is of critical importance in regulatory genomics\cite{Koo2020-vz,Novakovsky2022-ft,Talukder2021-wj}, but is often made challenging by the complexity of neural networks and methods for their interpretation. To address this in EUGENe, we created a standalone subpackage called SeqExplainer which makes various post-hoc interpretation strategies accessible to most PyTorch models trained on one-hot encoded genomic sequences (\url{https://github.com/ML4GLand/SeqExplainer}). SeqExplainer currently provides functionality for filter interpretation, attribution analysis, in silico experimentation, and sequence generation. Each strategy is briefly detailed below.

The interpretation of learned convolutional filters, commonly employed for model architectures that begin with a convolutional layer, involves using the set of sequences that significantly activate a given filter (maximally activating subsequences) to generate a position frequency matrix (PFM) (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{i}}). The PFM can then be converted to a position weight matrix (PWM), visualized as a sequence logo, and annotated with tools like TomTom\cite{Gupta2007-zw} using databases of known motifs such as JASPAR\cite{Castro-Mondragon2022-kx} or HOCOMOCO\cite{Kulakovskiy2018-oz}. Filter interpretation in this manner does have limitations. TomTom can be inaccurate when annotating motifs from learned filters\cite{Ullah2021-th,Koo2019-fb} and this analysis does not specify the importance of each filter for model predictions\cite{Koo2019-fb}. Despite these limitations, filter interpretation can be useful for hypothesis generation and for further exploration of how architecture affects learned representations\cite{Koo2019-fb,Koo2021-gs,Ploenzke2018-ng}.

Attribution analysis involves using the trained model to score every nucleotide of the input on how it influences the downstream prediction for that sequence (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{j}}). In SeqExplainer and EUGENe, we currently implement several common attribution approaches. These include standard in silico saturation mutagenesis (ISM), InputXGradient\cite{Shrikumar2016-lf}, DeepLIFT\cite{Shrikumar2016-lf}, and GradientSHAP\cite{Lundberg2017-hh}, with the latter three using functionality from the Captum package\cite{Kokhlikyan2020-mv}. Attributions can also be used to validate that the model has learned representations that resemble motifs. Unlike the filter interpretability approach described above, attributions are directly linked to model predictions, and can naturally be extended to model the effects of single nucleotide polymorphisms. However, attributions represent a “local,” often noisy\cite{Han2022-pi,Majdandzic2022-eu} interpretation of a single sequence, and can require clustering into “global” attributions for cleaner interpretation. In SeqExplainer, we offer wrappers for running the popular TF-MoDISco algorithm\cite{Shrikumar2018-sb} to accomplish this.

Attribution analysis, though very useful, stops short of quantifying the effect of whole motifs on model predictions. To get at the quantitative effects of such patterns, EUGENe offers a wide range of functionality for conducting in silico experiments with motifs of interest\cite{De_Almeida2022-aa,Avsec2021-sw}, also known as global importance analyses or GIAs\cite{Koo2021-ly}. Since the space of possible GIAs is essentially infinite, and the type of GIA used is often dependent on the data, model and biological question being asked, we provide the building blocks for GIAs in SeqExplainer, including functionality for generating background sequences and introducing perturbations (e.g., mutations, motif embedding, motif occlusion, etc.) to those sequences (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{k}}). EUGENe currently offers high-level functions for streamlining positional importance analysis (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{l}}) and distance-dependent motif cooperativity analysis, and we anticipate adding many more common GIAs to EUGENe in the future.

The last class of interpretability methods currently offered in EUGENe uses trained models to guide sequence evolution. We implement the simplest form of this approach that iteratively evolves a sequence by greedily inserting the mutation with the largest predicted impact at each iteration. Starting with an initial sequence (e.g., random, shuffled, etc.), this strategy can be used to evolve synthetic functional sequences\cite{Taskiran2022-zj} (\textbf{Figure~\ref{fig:1 Figure 5}\textbf{m}}). This style of analysis is a promising direction for further research and can also be used for validating that the model has learned representations that resemble motifs.

\subsection{Analysis of plant promoter data}

\subsubsection{Data acquisition and preprocessing}

Plant promoter assay data were obtained from the GitHub repository associated with Jores et al. These included two identical libraries for a set of 79,838 plant promoters synthesized with an upstream viral 35S enhancer and downstream barcode-tagged GFP reporter gene (\textbf{Figure~\ref{fig:1 Figure 2}\textbf{a}}). The libraries were designed to include 10–20 constructs with distinct barcodes for each promoter. These libraries were used to transiently transform both tobacco leaves and maize protoplasts, and promoter activities were assayed using plant STARR-seq\cite{Jores2020-hm}. Per-barcode activity was calculated as the ratio of RNA barcode frequency to DNA barcode frequency, and the median of these ratios was then used to aggregate across barcodes assigned to the same promoter. These aggregated scores were then normalized by the median value for a control construct and were log-transformed to calculate a per-promoter “enrichment” score. We downloaded these enrichment scores from the authors’ GitHub repository (\url{https://github.com/tobjores/Synthetic-Promoter-Designs-Enabled-by-a-Comprehensive-Analysis-of-Plant-Core-Promoters/tree/main/CNN}) for both libraries as separate datasets to use as training targets. We used the identical 90/10 training and test split used in Jores et al. (the dataset could be downloaded with set labels). The training set was further split into 90/10 train and validation sets. All sequences were one-hot encoded using a channel for each letter of the DNA alphabet (“ACGT”).

\subsubsection{Model initialization and training}

We implemented the Jores21CNN architecture by translating the Keras code in the associated GitHub repository into PyTorch and integrating it into our library. We benchmarked this architecture against built-in CNN, Hybrid, and DeepSTARR architectures in EUGENe with the hyperparameters described in \textbf{\textbf{Supplementary Data~1}}. In each convolutional layer, the Jores21CNN first applies a set of filters to the input as is standard for convolutional models, but also applies the reverse complements of the filters (as opposed to the reverse complement of the sequences) to each input in an effort to capture information from both strands\cite{Onimaru2020-do}. Since this still only requires a single strand as input into the models, we opted to benchmark against only single-stranded versions of built-in CNN and Hybrid models. Following instantiation, we initialized 78 filters in the first convolutional layer of each model using PWMs derived from core promoter elements and transcription factor binding clusters downloaded from the authors’ GitHub repository (\url{https://github.com/tobjores/Synthetic-Promoter-Designs-Enabled-by-a-Comprehensive-Analysis-of-Plant-Core-Promoters/tree/main/data/misc}). All other parameters were initialized by sampling from the Kaiming normal distribution\cite{He2015-qh}. We trained models for a maximum of 25 epochs with a batch size of 128 and used the Adam optimizer with a starting learning rate of 0.001. A learning rate scheduler with a patience of 2 epochs was included to adaptively decrease the learning rate. We used mean squared error as our objective function and stopped training early if the validation set error did not decrease after 5 epochs.

\subsubsection{Model evaluation and interpretation}

Models were primarily evaluated using the percentage of variance explained ($R^2$) on predictions for the test set. We repeated the above training procedure across 5 independent random initializations and evaluated $R^2$ scores across these trials. For PWM visualization, we used the approach described in Minnoye et al.\cite{Minnoye2020-vz} Briefly, for each filter in the first convolutional layer, we calculated activations for all subsequences (of the same length as the filter) within the test set sequences. We then took the top 100 subsequences corresponding to the top 100 activations (maximally activating subsequences) and generated a PFM. For visualizing filters as sequence logos, we converted PFMs to PWMs using a uniform background nucleotide frequency. We calculated attributions for all test set sequences using the DeepLIFT method\cite{Shrikumar2016-lf}. To perform the feature implantation approach, we downloaded the 16bp PFM containing the consensus TATA box motif from the Jores et al. GitHub repository and one-hot encoded it by taking the highest probability nucleotide at each position. We also downloaded the set of 310 promoters (\url{https://github.com/tobjores/Synthetic-Promoter-Designs-Enabled-by-a-Comprehensive-Analysis-of-Plant-Core-Promoters/blob/main/analysis/validation_sequences/promoters_for_evolution.tsv}) used in Jores et al. for in silico evolution. We then implanted the TATA box-containing sequence at every possible position of each of the 310 promoter sequences and used selected high-performing models (one each from leaf, protoplast, and combined) to make predictions. We compared this to predicted scores generated with the same feature implantation approach using a shuffled version of the 16bp sequence containing the TATA box motif, a random 16bp one-hot encoded sequence, and a 16bp all-zeros input. We performed the in silico evolution experiments on the same set of 310 promoter sequences\cite{Jores2021-iu}. In each round, we first used in silico saturation mutagenesis to identify the mutation that increased the model score by the largest positive value (delta score). We then introduced this mutation into the sequence and repeated this for 10 iterations.

\subsection{Analysis of RNA binding data}

\subsubsection{Data acquisition and preprocessing}

As described in detail in Alipanahi et al.\cite{Alipanahi2015-ef}, a set of 241{,}357 31--41\,nt RNA probes were split into two experimental sets, Set A and Set B, with each designed to include all possible 9-mers at least eight times, all possible 8-mers at least 33 times, and all possible 7-mers at least 155 times (\textbf{Figure~\ref{fig:1 Figure 3}\textbf{a}}). These probes were assayed against 244 RBPs using a protein binding microarray (PBM)\cite{Berger2009-la}, and intensities were normalized as described in Ray et al.\cite{Ray2013-yd}. We downloaded the normalized RNA probe binding intensity matrix from the Ray et al. supplementary data repository (\url{http://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/norm_data.txt.gz}) and separated the Set A and Set B sequences into two distinct groups. To remove outliers, we capped all probe intensity values at the 99.95th percentile for each RBP, and then Z-scored the clamped values to have zero mean and unit variance. All normalizations were performed using Set A statistics (i.e., Set B values were normalized using the means and standard deviations from Set A). For multitask prediction, we excluded 11 RBPs with $\geq$0.1\% missing values across Set A and removed all Set A probes with missing values for any of the remaining 233 RBPs. This resulted in 120{,}326 and 110{,}645 probes for training single-task and multitask models, respectively, and 121{,}031 probes in Set B for testing. Set A was then further split 80/20 into training and validation sets. All input sequences were one-hot encoded across the RNA alphabet (“ACGU”).

\subsubsection{Model initialization and training}

We implemented the DeepBind architecture described in the Supplementary Information (\url{https://static-content.springer.com/esm/art%3A10.1038%2Fnbt.3300/MediaObjects/41587_2015_BFnbt3300_MOESM51_ESM.pdf}) of Alipanahi et al.\ and added it to the EUGENe model library. DeepBind architectures were initially designed to take either the forward strand or both strands (ds) as input. However, since Alipanahi et al.\ trained their RBP models with just the single strand input (due to the single-stranded nature of RNA), we also used a single-stranded implementation for our DeepBind models. We initialized both the single-task models and the multitask model with parameters sampled from the Kaiming normal distribution\cite{He2015-qh} and trained all models for a maximum of 25 and 100 epochs, respectively, using the Adam optimizer\cite{Kingma2014-kn} and a starting learning rate of 0.005. We included a learning rate scheduler that reduced the learning rate with a patience of 2 epochs. The batch size was fixed to 64 and 1024 for the single- and multitask models, respectively. Mean squared error was used as the objective function, and training was halted early if the validation set error did not decrease after 5 epochs. For multitask models, we used the average mean squared error across all tasks. Hyperparameters for all model architectures are provided in \textbf{Supplementary Data 2}. Finally, we downloaded a set of 89 pretrained human RBP models from Kipoi (\url{https://kipoi.org/models/DeepBind/Homo_sapiens/RBP/}) and wrapped Kipoi functions to make predictions using these models.

\subsubsection{Model evaluation}

We evaluated models using the Z-score, AUC, and E-score metrics reported in Alipanahi et al. To calculate these metrics, we first computed a binary $n \times m$ matrix $A$, where the $n$ rows represent all possible 7-mers from the RNA alphabet (e.g., AAAAAAA, AAAAAAC, AAAAAAG, etc.) and the $m$ columns represent the 121{,}031 probes from Set B. Each entry $a_{ij}$ in the matrix is 1 if the $i$th k-mer is found in the $j$th probe, and 0 otherwise. For a single RBP, we have normalized binding intensity values across the 121{,}031 probes (denoted by the $m$-dimensional vector $x$). We compared each row of $A$ (i.e., each k-mer indicator vector) to $x$ and computed Z-scores, AUCs, and E-scores as described in \cite{Alipanahi2015-ef,Ray2013-yd}. This was repeated for all k-mers to generate an $n$-dimensional vector for each metric, reflecting that k-mer's contribution to binding by the RBP. For Z-scores, a value of 0 indicates average binding when the k-mer is present, with more positive values indicating stronger-than-average binding. AUC and E-scores (a variant of AUC) range from 0 to 1, with values closer to 1 indicating a strong association between k-mer presence and binding intensity. We repeated this procedure using predicted intensities from each model in place of the observed values, yielding a set of $n$-dimensional vectors for each model–metric pair. For each, we calculated Pearson and Spearman correlations with the observed vector $x$ to produce a pair of correlation values per RBP. These values are plotted as individual points in \textbf{Figure~\ref{fig:3 Figure 3}\textbf{b}} and \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}\textbf{a}}. Repeating this process across all RBPs results in a distribution of performance values for each model.

We applied the same procedure using Set A observed intensities to compute a distribution of correlations serving as a biological replicate baseline. These are shown as the “Set A” and “Observed intensities” columns in \textbf{Figure~\ref{fig:3 Figure 3}\textbf{b}} and \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}\textbf{a}}. The “Set A” distribution was computed using our own implementation, while the “Observed intensities” distribution was obtained from performance tables in the supplement of Alipanahi et al. Finally, we calculated Pearson and Spearman correlation coefficients between observed and predicted Set B intensities for all models. Because Set A and Set B contain different probe sequences, this comparison could not be performed on Set A, explaining the absence of “Set A” and “Observed intensities” in the final boxplots of \textbf{Figure~\ref{fig:3 Figure 3}\textbf{b}} and \textbf{Supplementary Figure~\ref{fig:1 supplementary_2}\textbf{a}}.

\subsubsection{Model interpretation}

For filter visualization, we used the approach described in Alipanahi et al. Briefly, for a given filter, we computed activation scores for all subsequences (of the same length as the filter) from Set B probes and identified the maximum activation. We then selected only those subsequences with activations at least three-fourths of this maximum to generate a position frequency matrix (PFM) for that filter. This process was repeated for all 16 filters in each of the top 10 single-task models and for all 1,024 filters of the multitask model. The top 10 single-task models were selected based on Pearson correlation between observed and predicted intensities. We annotated the multitask PFMs using TomTom against the Ray2013 \textit{Homo sapiens} database, retaining hits with Bonferroni-corrected $p$-values $\leq 0.05$. We computed attributions for all Set B probes using the InputXGradient method\cite{Shrikumar2016-lf}. For multitask models, attributions were calculated per task to determine how each input nucleotide contributed to the prediction for a specific RBP. We performed this analysis only for a subset of RBPs, again using Pearson correlation to select the top 10 single-task models and the top 10 best-predicted tasks in the multitask setting. We applied the same \textit{in silico} evolution procedure as described for the plant promoter use case. Using trained models for selected RBPs, we first generated 10 random 41-nt sequences (uniformly sampled from ``ACGT'') and conducted 5 rounds of evolution. In each round, we identified and applied the mutation that most increased model score. We then computed feature attributions for both the original and evolved sequences using the InputXGradient method and compared them.

\subsection{Analysis of JunD binding data}

\subsubsection{Data acquisition and preprocessing}

We followed the same procedure to acquire and preprocess the data for training models on the prediction of JunD binding as reported in Kopp et al.\cite{Kopp2020-fw} We started by downloading JunD peaks from human embryonic stem cells (H1-hESC) called with the hg38 reference genome from \texttt{encodeproject.org} (ENCFF446WOD, conservative IDR thresholded peaks, narrowPeak format). We next defined regions of interest (ROIs) by extending the union of all JunD peaks by 10\,kb in each direction. Blacklisted regions for hg38 (\url{http://mitra.stanford.edu/kundaje/akundaje/release/blacklists/hg38-human/hg38.blacklist.bed.gz}) were removed using \texttt{bedtools}\cite{Quinlan2010-ei}, and the resulting regions were trimmed to ensure divisibility into 200\,bp bins. For training and testing, we binned each ROI into 200\,bp sequences and labeled bins overlapping a JunD binding peak as positive and all others as negative. As input to the models, we extended each 200\,bp bin by 150\,bp on each side (producing a 500\,bp sequence) and one-hot encoded each sequence using one channel per DNA base (``ACGT''). In total, we generated 1,013,080 200\,bp bins to construct the training, validation, and test sets. Sequences were split by chromosome: validation sequences were drawn from chromosome 2, test sequences from chromosome 3, and the remainder were used for training.

\subsubsection{Model initialization and training}

For the JunD binding task, we implemented the Kopp21CNN architecture described in Kopp et al. by replicating the Keras code in their associated GitHub repository and the Supplementary Information \url{https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-020-17155-y/MediaObjects/41467_2020_17155_MOESM1_ESM.pdf}. We trained five random initializations each of dsFCN, dsCNN, dsHybrid, and Kopp21CNN architectures, initializing parameters with the Kaiming normal distribution.\cite{He2015-qh} All models were designed to receive both the forward and reverse strands as input via a shared architecture (ds). Following Kopp et al., we trained each model for a maximum of 30 epochs using the AMSGrad optimizer\cite{Phuong2019-dz} with a starting learning rate of 0.001. The batch size was fixed to 64, and binary cross-entropy was used as the loss function. Training was halted early if the validation loss did not decrease after five consecutive epochs. Hyperparameters for each model are provided in \textbf{\textbf{Supplementary Data 3}}.

\subsubsection{Model evaluation and interpretation}

Models were evaluated using the area under the precision-recall curve (auPRC) metric, as the dataset was substantially imbalanced. Model interpretation was performed using EUGENe’s attribution, filter visualization, and \textit{in silico} experimentation tools. Attributions for the forward and reverse strands of all test set sequences were computed using the GradientSHAP method.\cite{Lundberg2017-hh} For filter visualization, we applied the approach described previously and constructed position frequency matrices (PFMs). These PFMs were submitted to the TomTom webserver for annotation against the HOCOMOCO v11 FULL database,\cite{Kulakovskiy2018-oz} retaining only those hits with a Bonferroni-corrected $p$-value $\leq 0.05$. Logos were rendered using a uniform background nucleotide distribution. We also conducted an \textit{in silico} motif implantation experiment using the JunD PFM from JASPAR (\url{https://jaspar.genereg.net/matrix/MA0491.1}). We generated 10 random sequences by uniform sampling and implanted the one-hot encoded JunD consensus motif at every possible position. We compared predicted scores from these modified sequences to those generated from implanting a shuffled version of the motif, a completely random 10\,bp sequence, and a zero-valued 10\,bp input.

\subsection{Data visualization software}

For most exploratory data analysis and performance evaluations, we used a combination of the Seaborn and Matplotlib plotting libraries in Python. For sequence logo visualizations of filters and attributions, we used modified functions from the \texttt{viz\_sequence} package (\url{https://github.com/kundajelab/vizsequence}) and the \texttt{logomaker} package (\url{https://github.com/jbkinney/logomaker}).

\subsection{Statistical methods}

Mann-Whitney U tests\cite{Mann1947-dw} were used to compare performance distributions between architecture types, and $p$-values were corrected with the Benjamini-Hochberg method\cite{Benjamini1995-da}. TomTom reports the significance of alignments of query motifs to a database using the methods described in \cite{Gupta2007-zw}. We used the $q$-value reported by the webserver tool (\url{https://meme-suite.org/meme/tools/tomtom}) and considered hits to be those alignments with a $q$-value $\leq 0.05$ as significant. Figures for \textit{in silico} implantation of motifs included 95\% confidence intervals.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data availability}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All datasets used in this study are publicly available. Raw and processed data for the plant promoter STARR-seq were obtained from \url{https://github.com/tobjores/Synthetic-Promoter-Designs-Enabled-by-a-Comprehensive-Analysis-of-Plant-Core-Promoters}. Normalized RNA probe binding intensities were obtained from \url{http://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/norm_data.txt.gz}. JunD peaks from human embryonic stem cells (H1-hESC) called with the hg38 reference genome were obtained from \url{https://www.encodeproject.org/files/ENCFF446WOD/} (conservative IDR thresholded peaks, \texttt{narrowPeak} format). Blacklisted regions for hg38 were obtained from \url{http://mitra.stanford.edu/kundaje/akundaje/release/blacklists/hg38-human/hg38.blacklist.bed.gz}. TomTom queries were performed against the Ray2013 \textit{Homo sapiens} and the HOCOMOCO v11 FULL motif collections for the RBP binding and JunD binding use cases, respectively. The JunD PFM was obtained from \url{https://jaspar.genereg.net/matrix/MA0491.1} for the \textit{in silico} implantation experiment. A set of 89 RBP models was obtained from the Kipoi model repository at \url{https://kipoi.org/models/DeepBind/Homo_sapiens/RBP/}. We have also deposited the EUGENe-specific dataset files and trained models used in the analyses presented here on Zenodo\cite{Klie2023-vf}. These represent the processed data files and \texttt{SeqData} objects that can be used along with the accompanying code to generate the figures for all the use cases. Source data for \textbf{Figure~\ref{fig:1 Figure 2}}, \textbf{Figure~\ref{fig:3 Figure 3}}, and \textbf{Figure~\ref{fig:1 Figure 4}} is available with this manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Code availability}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

EUGENe is freely available under the MIT license at \url{https://github.com/ML4GLand/EUGENe}. The version of the codebase used for the analyses presented here is available on Zenodo\cite{Klie2023-gx}. Documentation for the tool is available at \url{https://eugene-tools.readthedocs.io/en/latest/index.html}. Jupyter notebooks and Python scripts used to perform the analyses presented here are available on GitHub at \url{https://github.com/ML4GLand/EUGENe_paper} (under the Creative Commons Zero v1.0 Universal license) and have been deposited on Zenodo\cite{Klie2023-ku}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This work was supported by the National Institutes of Health [grant number 1U01HG012059]; infrastructure was funded by the National Institutes of Health [grant number 2P41GM103504-11]; T.J. is supported by the German Research Foundation [DFG; fellowship number 441540116]. E.K.F and J.J.S were supported by the National Institutes of Health [grant number DP2HG010013]. H.C. is supported by the Canadian Institute for Advanced Research [award number FL-000655]. We would like to thank the community of genomics researchers who made their code open source so that we could utilize it for EUGENe functions.

The content of Chapter 1, in full, is a reformatted reprint of the material as it appears in “Predictive analyses of regulatory sequences with EUGENe" in \textit{Nature Computational Science}, 2023 by Adam Klie, David Laub, James V. Talwar, Hayden Stites, Tobias Jores, Joe J. Solvason, Emma K. Farley and Hannah Carter. The dissertation author was the primary investigator and author of this paper.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Author Contributions Statement}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A.K., J.J.S., E.K.F. and H.C. designed the study. A.K. designed the toolkit. A.K., D.L, J.T., and H.S. implemented the code. A.K. and D.L. performed the use case analyses. J.J.S., D.L., J.T., and H.S. performed software testing. H.C. supervised the work. All authors read and corrected the final manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Competing Interests Statement}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The authors declare no competing interests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Inclusion and Ethics Statement}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All research was conducted and is relevant locally. All author roles and responsibilities were agreed amongst collaborators.
